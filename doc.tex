
\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{geometry}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{listings}
\geometry{margin=2.5cm}

\title{Preprocesamiento Basado en Textura para la Segmentación de Tumores en Ecografías Mamarias con MONAI}
\author{María del Mar Ávila, Juan del Junco, Nerea Jiménez\\Tutora: María José Jiménez}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
El resumen se hace al final del trabajo
\end{abstract}

\textbf{Palabras clave:} segmentación, MONAI, características de textura, U-Net, preprocesamiento, ecografía mamaria.

\section{Introducción}
El cáncer de mama representa una de las principales causas de mortalidad femenina. La segmentación precisa de tumores en imágenes de ecografía mamaria es esencial para el diagnóstico asistido por computadora. Sin embargo, estas imágenes presentan artefactos, bajo contraste y ruido speckle que dificultan la segmentación automática. Este trabajo propone comparar métodos de preprocesamiento tradicionales y texturales para mejorar la calidad de segmentación utilizando una red U-Net.

\section{Planteamiento Teórico}

La inteligencia artificial ha transformado numerosas disciplinas, y la medicina no es la excepción. En particular, la segmentación automática de imágenes médicas se ha vuelto una herramienta de gran valor en el diagnóstico clínico. Este proyecto se centra en el preprocesamiento y la segmentación de tumores en ecografías mamarias utilizando una red neuronal llamada U-Net, entrenada con ayuda de la librería especializada MONAI.

\subsection{Preprocesamiento}

El preprocesamiento de las imágenes antes del entrenamiento es esencial para mejorar la calidad del aprendizaje. En este trabajo, se aplican técnicas como el redimensionamiento, la normalización de intensidades y filtros tradicionales para la reducción de ruido. Esto permite estandarizar los datos de entrada, mejorando la estabilidad y efectividad del modelo entrenado.

En concreto y en el ámbito que nos compete, las imágenes médicas presentan numerosos desafíos: pueden estar en distintos tamaños, tener ruido o intensidades mal distribuidas. Por eso, antes de alimentar la red neuronal, se aplican procesos de preprocesamiento que pueden incluir:

\begin{itemize}
  \item \textbf{Redimensionamiento de imágenes:} El redimensionamiento de las imágenes a un tamaño uniforme es un paso inicial crucial. Las imágenes originales pueden tener diferentes resoluciones, por lo que unificarlas facilita el procesamiento y reduce la carga computacional. Se utilizan técnicas de interpolación (como bilineal o bicúbica) para mantener la calidad de la imagen al cambiar su tamaño.

  \item \textbf{Normalización de intensidades:} La normalización consiste en escalar los valores de intensidad de píxel a un rango común, como [0,1]. Esto mejora la estabilidad y la eficiencia del entrenamiento del modelo, ya que reduce la variabilidad entre imágenes. Comúnmente se utiliza la normalización min-max o la estandarización basada en media y desviación estándar.

  \item \textbf{Filtro Butterworth:} El filtro Butterworth es un filtro frecuencial que puede funcionar como pasa-bajos o pasa-altos. Su principal ventaja es que proporciona una transición suave en la frecuencia de corte, evitando artefactos bruscos. El filtro pasa-bajos suaviza la imagen eliminando el ruido de alta frecuencia, mientras que el pasa-altos resalta los bordes. La forma matemática del filtro asegura que no haya una caída abrupta, manteniendo una transición gradual.

  \item \textbf{Filtro de mediana adaptativa:} Este filtro elimina eficazmente el ruido impulsivo (sal y pimienta) adaptando dinámicamente el tamaño de la ventana de filtrado. Si una ventana pequeña no es suficiente para identificar correctamente la mediana de los píxeles, el filtro aumenta el tamaño de la ventana hasta encontrar una mediana adecuada. Así, preserva los bordes y detalles mientras elimina el ruido localizado.

  \item \textbf{Características estadísticas de primer orden:} Estas características describen la distribución de las intensidades de los píxeles de forma individual, sin considerar su posición. Incluyen métricas como la media, varianza, asimetría, curtosis y entropía. Estas propiedades permiten caracterizar la luminosidad y el contraste general de la imagen.

  \item \textbf{Características estadísticas de segundo orden:} Se enfocan en las relaciones espaciales entre los píxeles. Se obtienen, por ejemplo, mediante la matriz de co-ocurrencia de niveles de gris (GLCM), que mide con qué frecuencia aparecen combinaciones de valores de gris a cierta distancia y dirección. A partir de esta matriz se calculan métricas como contraste, homogeneidad, energía y correlación, que describen patrones de textura en la imagen.
\end{itemize}

\subsection{Redes Neuronales Convolucionales (CNN)} 
Una \textbf{red neuronal convolucional} (o \textit{Convolutional Neural Network}, CNN) es un tipo de red de aprendizaje profundo especialmente adecuada para procesar imágenes. A diferencia de las redes totalmente conectadas, las CNN emplean \textit{capas convolucionales} que aplican filtros sobre la imagen para extraer automáticamente características locales (por ejemplo, bordes, texturas) y \textit{capas de pooling} para reducir la resolución espacial, preservando las características más relevantes. Esto permite aprender representaciones jerárquicas: las primeras capas detectan patrones simples y las más profundas combinan estas características en patrones complejos propios del contenido de la imagen. En resumen, una CNN es una arquitectura capaz de \textbf{aprender directamente a partir de los datos} de imagen, identificando patrones visuales útiles para la tarea dada.

En nuestro proyecto se utiliza una CNN para llevar a cabo la segmentación automática de tumores en ecografías mamarias. La red convolucional aprende a reconocer, píxel a píxel, qué regiones de la imagen corresponden a tejido tumoral y cuáles a tejido normal o fondo, a partir de ejemplos anotados. Gracias a las convoluciones, la red puede detectar las características visuales sutiles de un tumor en una ecografía (como variaciones de textura o bordes difusos). Este enfoque automatizado reemplaza la necesidad de definir manualmente criterios de segmentación, permitiendo que el modelo ``aprenda'' a partir de los datos.

\subsection*{Segmentación Semántica en Ecografías Mamarias}  
La \textbf{segmentación semántica} es una tarea de visión por computador que consiste en asignar una etiqueta de clase a cada píxel de una imagen mediante un algoritmo de aprendizaje profundo. En otras palabras, el resultado es una máscara donde cada píxel está clasificado como perteneciente a cierta categoría. En nuestro caso, trabajamos con una segmentación binaria: cada píxel de la ecografía se clasifica como “tumor” o “no tumor”.

Aplicada a \textbf{ecografías mamarias}, permite delimitar de forma precisa las lesiones tumorales en imágenes de ultrasonido. Estas imágenes suelen tener bajo contraste y presencia de ruido, lo que dificulta su interpretación. Mediante segmentación automática, el sistema aprende de ejemplos anotados a identificar patrones propios de los tumores. El resultado es una máscara que marca su ubicación y forma, lo cual puede acelerar y mejorar el diagnóstico clínico.

Para evaluar la calidad de la segmentación, el proyecto implementa métricas como el \textit{coeficiente de Dice} (DSC) y el \textit{Índice de Jaccard} (IoU), calculadas en el archivo \texttt{metrics\_evaluation.py}. Estas métricas comparan la superposición entre la predicción del modelo y la máscara real.

\subsection*{Arquitectura U-Net: Codificación, Decodificación y Conexiones de Salto}  
La arquitectura \textbf{U-Net} fue diseñada específicamente para segmentación de imágenes médicas. Tiene una forma en “U” compuesta por dos fases:

\begin{itemize}
  \item \textbf{Codificación (encoder)}: reduce progresivamente el tamaño de la imagen aplicando convoluciones y submuestreo (stride o pooling), extrayendo características globales.
  \item \textbf{Decodificación (decoder)}: reconstruye la resolución original mediante upsampling, refinando la predicción en cada paso.
\end{itemize}

Un elemento clave son las \textbf{conexiones de salto} (\textit{skip connections}), que copian los mapas de características del encoder y los concatenan con los del decoder en cada nivel. Esto permite recuperar detalles finos que se habrían perdido en el proceso de compresión, logrando una segmentación precisa, especialmente en bordes y estructuras pequeñas como los tumores.

\subsection*{Configuración Específica de U-Net empleada en el Proyecto}
El modelo se construye con la clase \texttt{UNet} de la librería MONAI, con la siguiente configuración:

\begin{itemize}
  \item \textbf{Espacio 2D}: \texttt{spatial\_dims=2}, adecuado para imágenes planas.
  \item \textbf{Canales}: Imagen de entrada en escala de grises (\texttt{in\_channels=1}) y salida binaria (\texttt{out\_channels=1}).
  \item \textbf{Estructura de capas}: Cuatro niveles con \texttt{channels=(16, 32, 64, 128)} y \texttt{strides=(2,2,2)} para reducir resolución.
  \item \textbf{Bloques residuales}: Se emplean bloques de dos convoluciones por nivel (\texttt{num\_res\_units=2}) que mejoran la estabilidad del entrenamiento.
  \item \textbf{Activaciones}: ReLU en capas intermedias; sigmoide al final para producir probabilidades píxel a píxel.
  \item \textbf{Función de pérdida}: \texttt{DiceLoss} con activación sigmoide incorporada.
  \item \textbf{Entrenamiento}: 15 épocas, batch size 2, optimizador Adam, con imágenes redimensionadas a 256x256 píxeles.
\end{itemize}

Este modelo, entrenado con imágenes del dataset BUSI y sus respectivas máscaras, se guarda como \texttt{unet\_busi.pt} y luego puede utilizarse para segmentar nuevas ecografías. La arquitectura, gracias a su simetría y al uso de conexiones de salto, ofrece segmentaciones precisas incluso en imágenes complejas y ruidosas como las ecografías mamarias.

\subsection*{Framework MONAI}
MONAI (Medical Open Network for AI) es una librería desarrollada para facilitar la implementación de modelos de aprendizaje profundo en el campo de la medicina. Extiende las funcionalidades de PyTorch con herramientas especializadas, incluyendo:

\begin{itemize}
    \item Transformaciones específicas para imágenes médicas (carga de datos, normalización, redimensionamiento).
    \item Modelos predefinidos como U-Net, V-Net y otros.
    \item Funciones de pérdida y métricas de evaluación adaptadas a segmentación.
    \item Integración con formatos de imagen médica (DICOM, NIfTI).
\end{itemize}

Gracias a MONAI, el desarrollo de este proyecto se beneficia de un entorno robusto y reproducible, permitiendo un enfoque modular y escalable para el tratamiento de imágenes médicas.

\section{Descripción del Proyecto}
Este proyecto se implementa en Python, utilizando OpenCV, NumPy, scikit-image y MONAI. El flujo de trabajo incluye:
\begin{itemize}
    \item Preprocesamiento de imágenes con filtros tradicionales y texturales.
    \item Fusión de canales para obtener imágenes RGB enriquecidas.
    \item Segmentación con una red U-Net.
    \item Evaluación de resultados con métricas clásicas.
\end{itemize}

\section{Metodología}
\subsection{Preprocesamiento}
Se aplican:
\begin{itemize}
    \item \textbf{Butterworth}: filtro pasa altos en dominio de frecuencia.
    \item \textbf{Mediana adaptativa}: reduce ruido speckle.
    \item \textbf{Primer orden}: media y entropía.
    \item \textbf{Segundo orden}: bordes (Canny) y Laplaciano como aproximación a autocorrelación y homogeneidad.
\end{itemize}

Las imágenes se fusionan en RGB: canal original + canal de textura 1 + canal de textura 2.

\subsection{Segmentación con U-Net}
La red U-Net se entrena con imágenes originales y preprocesadas. Se utilizan 30 épocas, tamaño de entrada 256x256, y pérdida DiceLoss. El modelo se evalúa con las métricas: Accuracy, IoU, DSC, Sensitivity, Specificity y Precision.

\section{Resultados}
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{comparacion_preprocessed.png}
\caption{Ejemplo de segmentación con imagen preprocesada por segundo orden}
\end{figure}

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Métrica} & \textbf{Original} & \textbf{Segundo Orden} \\
\hline
Global Accuracy & - & - \\
DSC & - & - \\
IoU & - & - \\
Precision & - & - \\
Sensitivity & - & - \\
Specificity & - & - \\
\hline
\end{tabular}
\caption{Comparación de métricas de segmentación entre métodos}
\end{table}

\section{Discusión}
Los resultados evidencian que las características de textura aumentan la diferenciación de tumores frente al fondo, mejorando la precisión de segmentación. La segunda orden destaca por resaltar bordes y contornos relevantes. Las métricas mejoran considerablemente frente a los métodos tradicionales.

\section{Conclusiones y Trabajo Futuro}
El preprocesamiento basado en textura mejora sustancialmente la segmentación en ecografías mamarias. Se propone, como trabajo futuro, probar este enfoque en otros órganos o técnicas de imagen, así como implementar GLCM completo para segundo orden.

\section{Autoevaluacion de cada miembro}

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Evalúa} & \textbf{Juan} & \textbf{Mar} & \textbf{Nerea} \\
\hline
Juan & - & - & - \\
Mar & - & - & - \\
Nerea & - & - & - \\
\hline
\end{tabular}
\caption{Evaluación entre compañeros}
\end{table}

\section{Tabla de tiempos}

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Tarea} & \textbf{Juan} & \textbf{Mar} & \textbf{Nerea} \\
\hline
Tarea 1 & - & - & - \\
Tarea 2 & - & - & - \\
Tarea 3 & - & - & - \\
Tarea 4 & - & - & - \\
Tarea 5 & - & - & - \\
Tarea 6 & - & - & - \\
\hline
\end{tabular}
\caption{Tiempo dedicado a cada tarea}
\end{table}

\section*{Bibliografía}
\begin{enumerate}
    \item S. Cai et al., "A Study on the Combination of Image Preprocessing Method Based on Texture Feature and Segmentation Algorithm for Breast Ultrasound Images", IEEE ICCECE, 2022.
    \item Yap, M. H. et al., "Automated breast ultrasound lesions detection using convolutional neural networks", IEEE JBHI, 2017.
    \item Ibtehaz, N. and Rahman, M. S., "MultiResUNet: Rethinking the U-Net architecture", Neural Networks, 2020.
    \item PyTorch. (s.f.). Tensors [Documentación]. Recuperado de \href{https://pytorch.org/docs/stable/tensors.html}{pytorch}
    \item Ronneberger, O., Fischer, P.,  Brox, T. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation. In Medical Image Computing and Computer-Assisted Intervention – MICCAI 2015
\end{enumerate}

\end{document}
